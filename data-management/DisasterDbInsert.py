import sys, os, csv, django, requests
import pandas as pd
import numpy as np
from django.db import transaction
from django.core.exceptions import ObjectDoesNotExist, MultipleObjectsReturned
from datetime import datetime

# í”„ë¡œì íŠ¸ ìµœìƒìœ„ í´ë”(ì—¬ê¸°ì„œëŠ” manage.pyê°€ ìˆëŠ” í´ë”)ë¥¼ sys.pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# 1. Django ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "config.settings")
django.setup()

# 2. models import (Django setup í›„!)
from disasters.models import CityCategory, AiDataset, DisasterCategory, DisasterDetail

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ CSV íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ì£¼ì†Œë¥¼ ì½ì–´ì™€ ì¹´ì¹´ì˜¤ë§µì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
def get_location_from_address(address):
    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {
        "Authorization": "KakaoAK ì„œë¹„ìŠ¤í‚¤", # ì—¬ê¸°ì— ë³¸ì¸ì˜ ì¹´ì¹´ì˜¤ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "KA": "sdk/1.0.0 os/python lang/en"
        }
    params = {"query": address}

    response = requests.get(url, headers=headers, params=params)
    result = response.json()

    if result.get("documents"):
        data = result["documents"][0]
        addr = data["address"]
        return {
            "latitude": addr["y"],
            "longitude": addr["x"],
            "region_1depth_name": addr["region_1depth_name"],
            "region_2depth_name": addr["region_2depth_name"],
            "region_3depth_name": addr["region_3depth_name"],
        }
    return None

"""
# ë„ì‹œ
csv_path = os.path.join(BASE_DIR, 'CityCategory_Data.csv')
with open(csv_path, newline='', encoding='utf-8-sig') as file:
    reader = csv.DictReader(file)
    print("CSV fieldnames:", reader.fieldnames)  # í—¤ë” í•„ë“œëª… ì¶œë ¥
    for row in reader:
        # rowê°€ ë¹„ì—ˆëŠ”ì§€ í™•ì¸ (ë¹ˆ ì¤„ì´ë©´ continue)
        if not any(row.values()):
            continue

        city_name1 = row['city_name1'].strip()
        city_name2 = row.get('city_name2', '').strip() or None

        # ì¤‘ë³µ í™•ì¸ (ì •í™•íˆ ë™ì¼í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€)
        exists = CityCategory.objects.filter(
            city_name1=city_name1,
            city_name2=city_name2
        ).exists()

        if exists:
            continue

        CityCategory.objects.get_or_create(
            city_name1=city_name1,
            city_name2=city_name2
        )



# ì¼ì¼ë‚ ì”¨ 
csv_path = os.path.join(BASE_DIR, '2023_2025_DayWeather.csv')
with open(csv_path, newline='', encoding='utf-8-sig') as file:
    reader = csv.DictReader(file)
    print("CSV fieldnames:", reader.fieldnames)  # í—¤ë” í•„ë“œëª… ì¶œë ¥
    for row in reader:
        # rowê°€ ë¹„ì—ˆëŠ”ì§€ í™•ì¸ (ë¹ˆ ì¤„ì´ë©´ continue)
        if not any(row.values()):
            continue

         # ë„ì‹œ ì°¾ê¸° (ì§€ì ëª… ê¸°ì¤€)
        city_name = row['ì§€ì ëª…'].strip()
        city = CityCategory.objects.filter(city_name2__icontains=city_name).first()

        if city_name == "ê´‘ì£¼":     # ì—¬ê¸°ì„œ ê´‘ì£¼ëŠ” ê´‘ì£¼ê´‘ì—­ì‹œë‹¤. ê²½ê¸°ë„ ê´‘ì£¼ì‹œë‘ ë‹¤ë¥´ë‹¤.
            city = CityCategory.objects.filter(city_name1__icontains=city_name).first()
        
        if not city:
            city = CityCategory.objects.filter(city_name1__icontains=city_name).first()
        if not city:
            print(f"[!] ë„ì‹œ '{city_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        
         # ë‚ ì§œ ë³€í™˜
        try:
            date = datetime.strptime(row['ì¼ì‹œ'].strip(), "%Y-%m-%d").date()
        except ValueError:
            print(f"[!] ë‚ ì§œ ì˜¤ë¥˜: {row['ì¼ì‹œ']}")
            continue

        # ê°’ ë³€í™˜
        exmn_tp = float(row['í‰ê· ê¸°ì˜¨(Â°C)']) if row['í‰ê· ê¸°ì˜¨(Â°C)'].strip() else None
        exmn_hmty = float(row['í‰ê·  ìƒëŒ€ìŠµë„(%)']) if row['í‰ê·  ìƒëŒ€ìŠµë„(%)'].strip() else None

        # ë‚ ì”¨ íŒë‹¨
        rain_val = row['ê°•ìˆ˜ ê³„ì†ì‹œê°„(hr)'].strip()
        snow_val = row['ì¼ ìµœì‹¬ì ì„¤(cm)'].strip()

        if rain_val and float(rain_val) > 0:
            weather = "rain"
        elif snow_val and float(snow_val) > 0:
            weather = "snow"
        else:
            weather = "sun"

        # í™”ì¬ ì—¬ë¶€ëŠ” ê¸°ë³¸ False
        fire_check = False

        #print(f"ë°ì´í„° ì‚½ì… {city_name} {city} {date}")
        # ì¤‘ë³µ í™•ì¸ (ì •í™•íˆ ë™ì¼í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€)
        exists = AiDataset.objects.filter(
            time=date,
            city=city
        ).exists()

        if exists:
            continue

        # ì €ì¥
        AiDataset.objects.create(
            time=date,
            city=city,
            exmn_tp=exmn_tp,
            exmn_hmty=exmn_hmty,
            weather=weather,
            fire_check=fire_check
        )



# ê²°ì¸¡ ë‚ ì§œë¥¼ ì „ë‚  í›„ë‚ ì˜ í‰ê· ìœ¼ë¡œ ë³´ì™„
# 1. ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
qs = AiDataset.objects.all().values()
df = pd.DataFrame.from_records(qs)
df['time'] = pd.to_datetime(df['time'])

# 2. ê·¸ë£¹í•‘ ë° ë³´ê°„ í•¨ìˆ˜ ì •ì˜
def interpolate_group(group):
    group = group.set_index('time')
    
    # ì¤‘ë³µëœ ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ê°’ë§Œ ì‚¬ìš©
    if group.index.duplicated().any():
        group = group[~group.index.duplicated(keep='first')]
    
    # ë‚ ì§œ ì „ì²´ ì±„ìš°ê¸° (ëˆ„ë½ëœ ë‚  í¬í•¨)
    full_index = pd.date_range(start=group.index.min(), end=group.index.max(), freq='D')
    group = group.reindex(full_index)
    
    # ì •ìˆ˜í˜• ì»¬ëŸ¼ ì²˜ë¦¬ ì£¼ì˜
    numeric_cols = ['exmn_hmty', 'exmn_tp']
    group[numeric_cols] = group[numeric_cols].interpolate(method='linear')
    
    # ë²”ì£¼í˜•(weather) ë³´ê°„ (ì• ê°’ìœ¼ë¡œ ì±„ì›€)
    group['weather'] = group['weather'].ffill().bfill()
    group['city_id'] = group['city_id'].ffill().bfill()  # city_idëŠ” ë™ì¼í•´ì•¼ í•˜ë¯€ë¡œ

    # ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ì»¬ëŸ¼ìœ¼ë¡œ ë³µì›
    group.reset_index(inplace=True)  # â† index â†’ time ì»¬ëŸ¼ìœ¼ë¡œ ë³µì›
    group.rename(columns={'index': 'time'}, inplace=True)  # ì¸ë±ìŠ¤ ì´ë¦„ ì§€ì •
    return group

# 3. city_id ë³„ë¡œ ë³´ê°„ ì ìš©
df_grouped = df.groupby('city_id', group_keys=False).apply(interpolate_group, include_groups=False).reset_index(level=0, drop=True).reset_index()

# 4. ê¸°ì¡´ì— ì—†ë˜ í–‰ë§Œ ì¶”ì¶œ
existing_dates = set(zip(df['time'], df['city_id']))
interpolated_dates = set(zip(df_grouped['time'], df_grouped['city_id']))

# ìƒˆë¡œ ìƒê¸´ ë³´ê°„ í–‰ë§Œ í•„í„°ë§
df_grouped['row_key'] = list(zip(df_grouped['time'], df_grouped['city_id']))
new_rows = df_grouped[df_grouped['row_key'].isin(interpolated_dates - existing_dates)].drop(columns='row_key')

# 5. ìƒˆ ê°ì²´ ìƒì„±
new_objs = []
for _, row in new_rows.iterrows():
    new_objs.append(AiDataset(
        time=row['time'].date(),
        exmn_hmty=row['exmn_hmty'],
        exmn_tp=row['exmn_tp'],
        weather=row['weather'],
        fire_check=False,
        city_id=int(row['city_id']),
    ))

AiDataset.objects.bulk_create(new_objs)



# ì—†ëŠ” ì‹œêµ°ì˜ ë°ì´í„°ë¥¼ ê·¼ì²˜ ìœ„ì¹˜ì˜ ë°ì´í„°ë¥¼ ë³µì‚¬í•´ ì¶”ê°€í•˜ê¸°
# ë„ì‹œ ID ê°€ì ¸ì˜¤ê¸° (ë˜ëŠ” city_nameìœ¼ë¡œ ê²€ìƒ‰)
city_pairs = {
    "ë™í•´ì‹œ": "ì‚¼ì²™ì‹œ",
    "ì›ì£¼ì‹œ": "íš¡ì„±êµ°",
    "ì¸ì œêµ°": "ì–‘êµ¬êµ°",
    "ì†ì´ˆì‹œ": ["ê³ ì„±êµ°", "ì–‘ì–‘êµ°"],     # ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê³ ì„±êµ°
    "ìˆ˜ì›ì‹œ": ["ì„±ë‚¨ì‹œ", "ì•ˆì–‘ì‹œ", "ì•ˆì‚°ì‹œ", "ê³¼ì²œì‹œ", "êµ°í¬ì‹œ", "ì˜ì™•ì‹œ", "ìš©ì¸ì‹œ", "í™”ì„±ì‹œ"],
    "ë™ë‘ì²œì‹œ": ["ì˜ì •ë¶€ì‹œ", "ì–‘ì£¼ì‹œ", "í¬ì²œì‹œ"],
    "ì¸ì²œê´‘ì—­ì‹œ": ["ë¶€ì²œì‹œ", "ì‹œí¥ì‹œ", "ê¹€í¬ì‹œ"],
    "ì„œìš¸íŠ¹ë³„ì‹œ": ["ê´‘ëª…ì‹œ", "ê³ ì–‘ì‹œ", "êµ¬ë¦¬ì‹œ", "ë‚¨ì–‘ì£¼ì‹œ", "ì˜¤ì‚°ì‹œ"],
    "ì²œì•ˆì‹œ": ["í‰íƒì‹œ", "ì•ˆì„±ì‹œ", "ì•„ì‚°ì‹œ", "ì§„ì²œêµ°"],
    "ì–‘í‰êµ°": ["í•˜ë‚¨ì‹œ", "ê´‘ì£¼ì‹œ"],
    "ì´ì²œì‹œ": "ì—¬ì£¼ì‹œ",
    "ì² ì›êµ°": "ì—°ì²œêµ°",
    "ì¶˜ì²œì‹œ": "ê°€í‰êµ°",
    "ë‚¨í•´êµ°": "ì‚¬ì²œì‹œ",
    "ì˜ë ¹êµ°": "í•¨ì•ˆêµ°",
    "ë°€ì–‘ì‹œ": ["ì°½ë…•êµ°", "ì²­ë„êµ°"],
    "í†µì˜ì‹œ": "ê³ ì„±êµ°",     # ê²½ìƒë‚¨ë„ ê³ ì„±êµ°
    "ê´‘ì–‘ì‹œ": "í•˜ë™êµ°",
    "ì˜ë™êµ°": "ê¹€ì²œì‹œ",
    "ì•ˆë™ì‹œ": ["ì˜ì„±êµ°", "ì˜ˆì²œêµ°"],
    "ì²­ì†¡êµ°": "ì˜ì–‘êµ°",
    "í•©ì²œêµ°": "ê³ ë ¹êµ°",
    "êµ¬ë¯¸ì‹œ": ["ì„±ì£¼êµ°", "ì¹ ê³¡êµ°"],
    "ëŒ€êµ¬ê´‘ì—­ì‹œ": "ê²½ì‚°ì‹œ",
    "ê´‘ì£¼ê´‘ì—­ì‹œ": ["ë‚˜ì£¼ì‹œ", "í™”ìˆœêµ°"],
    "ìˆœì°½êµ°": ["ë‹´ì–‘êµ°", "ê³¡ì„±êµ°"],
    "ìˆœì²œì‹œ": "êµ¬ë¡€êµ°",
    "ê°•ì§„êµ°": "ì˜ì•”êµ°",
    "ëª©í¬ì‹œ": ["ì‹ ì•ˆêµ°", "ë¬´ì•ˆêµ°"],
    "ì˜ê´‘êµ°": "í•¨í‰êµ°",
    "ì „ì£¼ì‹œ": ["ìµì‚°ì‹œ", "ì™„ì£¼êµ°"],
    "ë¶€ì•ˆêµ°": "ê¹€ì œì‹œ",
    "ê¸ˆì‚°êµ°": "ë¬´ì£¼êµ°",
    "ì¥ìˆ˜êµ°": "ì§„ì•ˆêµ°",
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": "ê³µì£¼ì‹œ",
    "ë¶€ì—¬êµ°": ["ë…¼ì‚°ì‹œ", "ì²­ì–‘êµ°"],
    "ëŒ€ì „ê´‘ì—­ì‹œ": ["ê³„ë£¡ì‹œ", "ì˜¥ì²œêµ°"],
    "ì„œì‚°ì‹œ": ["ë‹¹ì§„ì‹œ", "íƒœì•ˆêµ°"],
    "êµ°ì‚°ì‹œ": "ì„œì²œêµ°",
    "í™ì„±êµ°": "ì˜ˆì‚°êµ°",
    "ì¶©ì£¼ì‹œ": ["ê´´ì‚°êµ°", "ìŒì„±êµ°"],
    "ì˜ì£¼ì‹œ": "ë‹¨ì–‘êµ°",
    "ì²­ì£¼ì‹œ": "ì¦í‰êµ°",
}

@transaction.atomic
def copy_many_weather_pairs(city_pairs):
    for from_name, to_names in city_pairs.items():
        # ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤Œ
        if isinstance(to_names, str):
            to_names = [to_names]

        # from_city ì°¾ê¸°
        from_city = None
        try:
            from_city = CityCategory.objects.get(city_name2=from_name)
        except ObjectDoesNotExist:
            try:
                from_city = CityCategory.objects.get(city_name1=from_name)
            except ObjectDoesNotExist:
                print(f"[!] ë„ì‹œ '{from_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (1)")
                continue

        for to_name in to_names:
            to_city = None
            try:
                to_city = CityCategory.objects.get(city_name2=to_name)
            except ObjectDoesNotExist:
                try:
                    to_city = CityCategory.objects.get(city_name1=to_name)
                except ObjectDoesNotExist:
                    print(f"[!] ë„ì‹œ '{to_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (2)")
                    continue
            except MultipleObjectsReturned:
                if from_name == "ì†ì´ˆì‹œ":   # ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê³ ì„±êµ°
                    to_city = CityCategory.objects.get(city_name1="ê°•ì›íŠ¹ë³„ìì¹˜ë„", city_name2=to_name)
                elif from_name == "í†µì˜ì‹œ": # ê²½ìƒë‚¨ë„ ê³ ì„±êµ°
                    to_city = CityCategory.objects.get(city_name1="ê²½ìƒë‚¨ë„", city_name2=to_name)
                else:
                    print(f"[!] ë„ì‹œ '{to_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!. (3)")
                    continue



            print(f"ğŸ“¦ ë³µì‚¬: {from_name} â†’ {to_name}")

            # to_cityì— ì´ë¯¸ ìˆëŠ” ë‚ ì§œëŠ” ì œì™¸
            to_dates = set(
                AiDataset.objects.filter(city=to_city).values_list("time", flat=True)
            )

            # from_cityì˜ ë°ì´í„° ì¤‘ì—ì„œ to_cityì— ì—†ëŠ” ë‚ ì§œë§Œ ë³µì‚¬
            from_entries = AiDataset.objects.filter(city=from_city).exclude(time__in=to_dates)

            new_data = [
                AiDataset(
                    time=entry.time,
                    city=to_city,
                    exmn_hmty=entry.exmn_hmty,
                    exmn_tp=entry.exmn_tp,
                    weather=entry.weather,
                    fire_check=entry.fire_check
                )
                for entry in from_entries
            ]

            AiDataset.objects.bulk_create(new_data, batch_size=500)

copy_many_weather_pairs(city_pairs)


# ì‚°ë¶ˆ ì •ë³´ë¥¼ ì½ì–´ì„œ fire_checkë¥¼ True ì‹œí‚¨ë‹¤.
@transaction.atomic
def mark_fire_check_from_csv(file_path):
    with open(file_path, newline='', encoding='utf-8-sig') as csvfile:
        reader = csv.DictReader(csvfile)

        for row in reader:
            address = row['FRSTFR_DCLR_ADDR']   # ì‚°ë¶ˆì‹ ê³ ì£¼ì†Œ
            date_str = row['FRSTFR_GNT_DT']     # ì‚°ë¶ˆë°œí™”ì¼ì‹œ
            date = datetime.strptime(date_str, "%Y-%m-%d").date()

            # ì£¼ì†Œì—ì„œ ì‹œ/êµ° ì¶”ì¶œ (ì˜ˆ: "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì–‘ì–‘êµ°..." â†’ "ê°•ì›íŠ¹ë³„ìì¹˜ë„" "ì–‘ì–‘êµ°")
            parts = address.split()
            city_keyword1 = None
            city_keyword2 = None

            no_keyword2 = [
                "ê´‘ì£¼ê´‘ì—­ì‹œ",
                "ëŒ€êµ¬ê´‘ì—­ì‹œ",
                "ëŒ€ì „ê´‘ì—­ì‹œ",
                "ë¶€ì‚°ê´‘ì—­ì‹œ",
                "ì„œìš¸íŠ¹ë³„ì‹œ",
                "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
                "ìš¸ì‚°ê´‘ì—­ì‹œ",
                "ì¸ì²œê´‘ì—­ì‹œ",
            ]
            # ì‹œ, êµ° ë¶€ë¶„ ë¹¼ê¸°. ì„œìš¸ì‹œì™€ ì„œìš¸íŠ¹ë³„ì‹œ ë‘˜ë‹¤ ë“¤ì–´ìˆê¸° ë•Œë¬¸ì— 'ì„œìš¸'ë¡œ like ì°¾ê¸° ìœ„í•´
            for index, p in enumerate(parts):
                if index == 0:
                    stop = False
                    city_keyword1 = p[:-1]
                    for strNo in no_keyword2:
                        if city_keyword1 in strNo:
                            stop = True
                            break
                    if stop == True:
                        break
                elif index == 1:
                    if len(p) > 3:
                        city_keyword2 = p[:3]
                    else:
                        city_keyword2 = p[:-1]
                    break

            if not city_keyword1:
                print(f"[!] ì£¼ì†Œì—ì„œ ë„ì‹œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {address}")
                continue

            # ë„ì‹œ ê²€ìƒ‰
            city = None

            try:
                if city_keyword2:
                    city = CityCategory.objects.get(city_name2__icontains=city_keyword2)
                else:
                    city = CityCategory.objects.get(city_name1__icontains=city_keyword1)
            except ObjectDoesNotExist:
                try:
                    data = get_location_from_address(address.strip())
                    if data == None:
                        print(f"[!] ë„ì‹œ ë¯¸ë°œê²¬1-1: {address.strip()}")
                        continue
                    print(f"ë„ì‹œ ë¯¸ë°œê²¬ì´ë¼ ì¹´ì¹´ì˜¤ë§µìœ¼ë¡œ ì°¾ì•„ë´„. {data['region_1depth_name']} {data['region_2depth_name']} {data['region_3depth_name']}")
                    print(f"region_2depth_name: {repr(data['region_2depth_name'])}")
                    city_keyword2 = str(data["region_2depth_name"]).strip()[:3]
                    city = CityCategory.objects.get(city_name2__icontains=city_keyword2)
                except ObjectDoesNotExist:
                    city_keyword1 = str(data["region_1depth_name"]).strip()[:2]
                    city = CityCategory.objects.get(city_name1__icontains=city_keyword1)
                except MultipleObjectsReturned:
                    print(f"[!] ë„ì‹œ ë¯¸ë°œê²¬1-2: {city_keyword1} {city_keyword2}")
                    continue
            except MultipleObjectsReturned:
                if "ê°•ì›" in city_keyword1:   # ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê³ ì„±êµ°
                    city = CityCategory.objects.get(city_name1="ê°•ì›íŠ¹ë³„ìì¹˜ë„", city_name2__icontains=city_keyword2)
                elif "ê²½ìƒë‚¨" in city_keyword1: # ê²½ìƒë‚¨ë„ ê³ ì„±êµ°
                    city = CityCategory.objects.get(city_name1="ê²½ìƒë‚¨ë„", city_name2__icontains=city_keyword2)
                elif "ì–‘ì£¼" == city_keyword2: # ê²½ê¸°ë„ ì–‘ì£¼ì‹œ. ê²½ê¸°ë„ì—ëŠ” ë‚¨ì–‘ì£¼ì‹œì™€ ì–‘ì£¼ì‹œê°€ ìˆë‹¤. ë‚¨ì–‘ì£¼ì‹œëŠ” ì˜ ë“¤ì–´ê°ˆ í…Œë‹ˆ ì–‘ì£¼ì‹œë¥¼ ë„£ëŠ”ë‹¤.
                    city = CityCategory.objects.get(city_name1="ê²½ê¸°ë„", city_name2="ì–‘ì£¼ì‹œ")
                else:
                    print(f"[!] ë„ì‹œ ë¯¸ë°œê²¬2: {city_keyword1} {city_keyword2}")
                    continue

            if not city:
                print(f"[!] ë„ì‹œ ë¯¸ë°œê²¬3: {city_keyword1} {city_keyword2}")
                continue

            # AiDataset ì—…ë°ì´íŠ¸
            updated = AiDataset.objects.filter(city=city, time=date).update(fire_check=True)
            if updated:
                print(f"âœ… {city_keyword1} {city_keyword2} / {date} â†’ fire_check = True")
            else:
                print(f"âš ï¸  í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ì—†ìŒ: {city_keyword1} {city_keyword2} / {date}")

# ì‚¬ìš© ì˜ˆì‹œ
csv_path = os.path.join(BASE_DIR, 'FireMountain_Data.csv')
mark_fire_check_from_csv(csv_path)



# í™”ì¬ìœ í˜•
csv_path = os.path.join(BASE_DIR, 'í™”ì¬í†µê³„/í™”ì¬ìœ í˜•.csv')
with open(csv_path, newline='', encoding='utf-8-sig') as file:
    reader = csv.DictReader(file)
    print("CSV fieldnames:", reader.fieldnames)  # í—¤ë” í•„ë“œëª… ì¶œë ¥
    for row in reader:
        # rowê°€ ë¹„ì—ˆëŠ”ì§€ í™•ì¸ (ë¹ˆ ì¤„ì´ë©´ continue)
        if not any(row.values()):
            continue

        # í™”ì¬ìœ í˜• ê°€ì ¸ì˜¤ê¸°
        name = row['í™”ì¬ìœ í˜•'].strip()

        # ì¤‘ë³µ í™•ì¸ (ì •í™•íˆ ë™ì¼í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€)
        exists = DisasterCategory.objects.filter(
            name=name
        ).exists()

        if exists:
            continue

        # ì €ì¥.
        # ì•„ì§ í”½í† ê·¸ë¨ ì´ë¯¸ì§€ê°€ ì—†ì–´ì„œ ì„ì‹œë¡œ ë„£ìŒ.
        DisasterCategory.objects.create(
            name=name,
            pictogram_image="pictogram_image"
        )


# í™”ì¬í†µê³„
@transaction.atomic
def insert_firedetail_from_csv(file_path):
    with open(csv_path, newline='', encoding='utf-8-sig') as file:
        reader = csv.DictReader(file)
        print("CSV fieldnames:", reader.fieldnames)  # í—¤ë” í•„ë“œëª… ì¶œë ¥
        for row in reader:
            # rowê°€ ë¹„ì—ˆëŠ”ì§€ í™•ì¸ (ë¹ˆ ì¤„ì´ë©´ continue)
            if not any(row.values()):
                continue

            # í™”ì¬ìœ í˜•
            category_name = row['í™”ì¬ìœ í˜•'].strip()
            category = DisasterCategory.objects.filter(name=category_name).first()

            if not category:
                print(f"[!] ë„ì‹œ '{category_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # ë„ì‹œ ì°¾ê¸° (ì§€ì ëª… ê¸°ì¤€)
            city_keyword1 = row['ì‹œë„'].strip()[:-1]
            city_keyword2 = row['ì‹œ_êµ°_êµ¬'].strip()[:3]

            # ë„ì‹œ ê²€ìƒ‰
            city = None

            try:
                city = CityCategory.objects.get(city_name2__icontains=city_keyword2)
            except ObjectDoesNotExist:
                try:
                    city = CityCategory.objects.get(city_name1__icontains=city_keyword1)
                except ObjectDoesNotExist:
                    data = get_location_from_address(city_keyword1 + ' ' + city_keyword2)
                    if data == None:
                        print(f"[!] ë„ì‹œ ë¯¸ë°œê²¬1-1: {city_keyword1 + ' ' + city_keyword2}")
                        continue
                    print(f"ë„ì‹œ ë¯¸ë°œê²¬ì´ë¼ ì¹´ì¹´ì˜¤ë§µìœ¼ë¡œ ì°¾ì•„ë´„. {data['region_1depth_name']} {data['region_2depth_name']} {data['region_3depth_name']}")
                    print(f"region_2depth_name: {repr(data['region_2depth_name'])}")
                    city_keyword2 = str(data["region_2depth_name"]).strip()[:3]
                    # city_keyword1 = str(data["region_1depth_name"]).strip()[:2]
                    city = CityCategory.objects.get(city_name2__icontains=city_keyword2)
                except MultipleObjectsReturned:
                    if city_keyword2 == "êµ°ìœ„êµ°":      # êµ°ìœ„êµ°ì€ 2023ë…„ 7ì›” 1ì¼ë¶€í„° ëŒ€êµ¬ê´‘ì—­ì‹œë¡œ í¸ì…ë˜ì—ˆë‹¤.
                        city = CityCategory.objects.get(city_name1="ëŒ€êµ¬ê´‘ì—­ì‹œ")
                    else:
                        print(f"[!] ë„ì‹œ ë¯¸ë°œê²¬1-2: {city_keyword1} {city_keyword2}")
                        continue
            except MultipleObjectsReturned:
                if "ê°•ì›" in city_keyword1:   # ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê³ ì„±êµ°
                    city = CityCategory.objects.get(city_name1="ê°•ì›íŠ¹ë³„ìì¹˜ë„", city_name2__icontains=city_keyword2)
                elif "ê²½ìƒë‚¨" in city_keyword1: # ê²½ìƒë‚¨ë„ ê³ ì„±êµ°
                    city = CityCategory.objects.get(city_name1="ê²½ìƒë‚¨ë„", city_name2__icontains=city_keyword2)
                elif "ì–‘ì£¼ì‹œ" == city_keyword2: # ê²½ê¸°ë„ ì–‘ì£¼ì‹œ. ê²½ê¸°ë„ì—ëŠ” ë‚¨ì–‘ì£¼ì‹œì™€ ì–‘ì£¼ì‹œê°€ ìˆë‹¤. ë‚¨ì–‘ì£¼ì‹œëŠ” ì˜ ë“¤ì–´ê°ˆ í…Œë‹ˆ ì–‘ì£¼ì‹œë¥¼ ë„£ëŠ”ë‹¤.
                    city = CityCategory.objects.get(city_name1="ê²½ê¸°ë„", city_name2="ì–‘ì£¼ì‹œ")
                else:
                    print(f"[!] ë„ì‹œ ë¯¸ë°œê²¬2: {city_keyword1} {city_keyword2}")
                    continue

            if not city:
                print(f"[!] ë„ì‹œ ë¯¸ë°œê²¬3: {city_keyword1} {city_keyword2}")
                continue
            
            
            # ë‚ ì§œ ë³€í™˜
            try:
                date = datetime.strptime(row['ì¼ì‹œ'].strip(), "%Y-%m-%d").date()
            except ValueError:
                print(f"[!] ë‚ ì§œ ì˜¤ë¥˜: {row['ì¼ì‹œ']}")
                continue

            # ë°œí™”ìš”ì¸
            caused = row['ë°œí™”ìš”ì¸ëŒ€ë¶„ë¥˜'].strip()

            # ê°’ ë³€í™˜
            casualty = int(row['ì¸ëª…í”¼í•´(ëª…)ì†Œê³„']) if row['ì¸ëª…í”¼í•´(ëª…)ì†Œê³„'].strip() else None
            scale = int(row['ì¬ì‚°í”¼í•´ì†Œê³„']) if row['ì¬ì‚°í”¼í•´ì†Œê³„'].strip() else None

            #print(f"ë°ì´í„° ì‚½ì… {city_name} {city} {date}")
            # ì¤‘ë³µ í™•ì¸ (ì •í™•íˆ ë™ì¼í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€)
            exists = DisasterDetail.objects.filter(
                occurrence_time=date,
                city=city
            ).exists()

            if exists:
                continue

            # ì €ì¥
            DisasterDetail.objects.create(
                category = category,
                city = city,
                occurrence_time = date,
                scale = scale,
                casualty = casualty, 
                caused = caused,
                status = "ì§„í™”ì™„ë£Œ",
            )

csv_names = [
    "2018ë…„ í™”ì¬.csv",
    "2019ë…„ í™”ì¬.csv",
    "2020ë…„ ì—°ê°„í™”ì¬í†µê³„.csv",
    "2021ë…„ ì—°ê°„í™”ì¬í†µê³„.csv",
    "ì†Œë°©ì²­_ì—°ê°„í™”ì¬í†µê³„_20221231.csv",
    "ì†Œë°©ì²­_ì—°ê°„í™”ì¬í†µê³„_20231231.csv"
]
for cn in csv_names:
    csv_path = os.path.join(BASE_DIR, 'í™”ì¬í†µê³„/' + cn)
    insert_firedetail_from_csv(csv_path)

"""
